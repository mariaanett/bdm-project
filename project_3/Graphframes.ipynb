{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Big graphs\n",
    "\n",
    "The objective of this project is to use Sparkâ€™s APIs to analyze the flight interconnected data to understand the popularity of the airports and flight patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "# Prepare the Spark builder\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"Project_3\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder,extra_packages=[\"graphframes:graphframes:0.8.4-spark3.5-s_2.12\"]).getOrCreate()\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", spark._sc.defaultParallelism)\n",
    "\n",
    "#spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True) # OK for exploration, not great for performance\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.truncate\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphframes as gf\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92b18f53-5683-43db-bf6e-2080eebf8afc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Creating the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b44e89e-57ea-4cda-9dde-935a1d203fbd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[FL_DATE: date, OP_CARRIER: string, OP_CARRIER_FL_NUM: int, ORIGIN: string, DEST: string, CRS_DEP_TIME: int, DEP_TIME: double, DEP_DELAY: double, TAXI_OUT: double, WHEELS_OFF: double, WHEELS_ON: double, TAXI_IN: double, CRS_ARR_TIME: int, ARR_TIME: double, ARR_DELAY: double, CANCELLED: double, CANCELLATION_CODE: string, DIVERTED: double, CRS_ELAPSED_TIME: double, ACTUAL_ELAPSED_TIME: double, AIR_TIME: double, DISTANCE: double, CARRIER_DELAY: double, WEATHER_DELAY: double, NAS_DELAY: double, SECURITY_DELAY: double, LATE_AIRCRAFT_DELAY: double, Unnamed: 27: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading in the data\n",
    "\n",
    "flight_df = spark.read.csv(\"input/2009.csv\", header=True, inferSchema=True)\n",
    "display(flight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e400236-cfae-49b6-a7f8-55b58070ff2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vertices\n",
    "\n",
    "flight_vertices = (flight_df\n",
    "                  .select(F.col(\"ORIGIN\").alias(\"id\"))\n",
    "                  .union(flight_df\n",
    "                        .select(F.col(\"DEST\").alias(\"id\")))\n",
    "                  .distinct()\n",
    ")\n",
    "\n",
    "display(flight_vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3845e9a6-68ee-4247-a2a0-695c2625e7bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[FL_DATE: date, OP_CARRIER: string, OP_CARRIER_FL_NUM: int, src: string, dst: string, CRS_DEP_TIME: int, DEP_TIME: double, DEP_DELAY: double, TAXI_OUT: double, WHEELS_OFF: double, WHEELS_ON: double, TAXI_IN: double, CRS_ARR_TIME: int, ARR_TIME: double, ARR_DELAY: double, CANCELLED: double, CANCELLATION_CODE: string, DIVERTED: double, CRS_ELAPSED_TIME: double, ACTUAL_ELAPSED_TIME: double, AIR_TIME: double, DISTANCE: double, CARRIER_DELAY: double, WEATHER_DELAY: double, NAS_DELAY: double, SECURITY_DELAY: double, LATE_AIRCRAFT_DELAY: double, Unnamed: 27: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Edges\n",
    "\n",
    "flight_edges = (flight_df\n",
    "               .withColumnRenamed(\"ORIGIN\",\"src\")\n",
    "               .withColumnRenamed(\"DEST\",\"dst\")\n",
    ")\n",
    "\n",
    "display(flight_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GraphFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dedad5cc-a634-42d4-bac8-e24c2853ffa9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphFrame(v:[id: string], e:[src: string, dst: string ... 26 more fields])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flight_graph = gf.GraphFrame(flight_vertices, flight_edges)\n",
    "\n",
    "flight_vertices.cache()\n",
    "flight_edges.cache()\n",
    "\n",
    "display(flight_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acb9f1ff-a64d-4dab-9835-bb97e1e5323c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Query 1 (0)\n",
    "\n",
    "Compute different statistics : in-degree, out-degree and total degree (without existing functions). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|dst|inDegree|\n",
      "+---+--------+\n",
      "|IAH|  182088|\n",
      "|JAX|   28813|\n",
      "|ABQ|   35577|\n",
      "|IND|   38198|\n",
      "|BOS|  110463|\n",
      "|GRR|   13970|\n",
      "|MEM|   71721|\n",
      "|PBI|   25496|\n",
      "|XNA|   13764|\n",
      "|LBB|    8004|\n",
      "|BTV|    6021|\n",
      "|VPS|    6958|\n",
      "|SYR|    9330|\n",
      "|JFK|  119571|\n",
      "|MBS|    3443|\n",
      "|SBN|    4527|\n",
      "|PDX|   52251|\n",
      "|RDD|    1433|\n",
      "|LNK|    2765|\n",
      "|HPN|   10661|\n",
      "+---+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_degree = flight_graph.edges.groupBy(\"dst\").agg(F.count(\"*\").alias(\"inDegree\"))\n",
    "\n",
    "in_degree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|inDegree|\n",
      "+---+--------+\n",
      "|IAH|  182088|\n",
      "|JAX|   28813|\n",
      "|ABQ|   35577|\n",
      "|IND|   38198|\n",
      "|BOS|  110463|\n",
      "|GRR|   13970|\n",
      "|MEM|   71721|\n",
      "|PBI|   25496|\n",
      "|XNA|   13764|\n",
      "|LBB|    8004|\n",
      "|BTV|    6021|\n",
      "|VPS|    6958|\n",
      "|SYR|    9330|\n",
      "|JFK|  119571|\n",
      "|MBS|    3443|\n",
      "|SBN|    4527|\n",
      "|PDX|   52251|\n",
      "|RDD|    1433|\n",
      "|LNK|    2765|\n",
      "|HPN|   10661|\n",
      "+---+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For validation\n",
    "flight_graph.inDegrees.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "|src|outDegree|\n",
      "+---+---------+\n",
      "|IAH|   182097|\n",
      "|JAX|    28810|\n",
      "|ABQ|    35582|\n",
      "|IND|    38201|\n",
      "|GRR|    13973|\n",
      "|LBB|     8002|\n",
      "|MEM|    71713|\n",
      "|BTV|     6028|\n",
      "|BOS|   110460|\n",
      "|PBI|    25500|\n",
      "|XNA|    13755|\n",
      "|VPS|     6959|\n",
      "|SYR|     9336|\n",
      "|JFK|   119574|\n",
      "|MBS|     3444|\n",
      "|SBN|     4526|\n",
      "|PDX|    52242|\n",
      "|RDD|     1433|\n",
      "|LNK|     2765|\n",
      "|HPN|    10657|\n",
      "+---+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_degree = flight_graph.edges.groupBy(\"src\").agg(F.count(\"*\").alias(\"outDegree\"))\n",
    "out_degree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|outDegree|\n",
      "+---+---------+\n",
      "|IAH|   182097|\n",
      "|JAX|    28810|\n",
      "|ABQ|    35582|\n",
      "|IND|    38201|\n",
      "|GRR|    13973|\n",
      "|LBB|     8002|\n",
      "|MEM|    71713|\n",
      "|BTV|     6028|\n",
      "|BOS|   110460|\n",
      "|PBI|    25500|\n",
      "|XNA|    13755|\n",
      "|VPS|     6959|\n",
      "|SYR|     9336|\n",
      "|JFK|   119574|\n",
      "|MBS|     3444|\n",
      "|SBN|     4526|\n",
      "|PDX|    52242|\n",
      "|RDD|     1433|\n",
      "|LNK|     2765|\n",
      "|HPN|    10657|\n",
      "+---+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For validation\n",
    "flight_graph.outDegrees.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|degree|\n",
      "+---+------+\n",
      "|IAH|364185|\n",
      "|JAX| 57623|\n",
      "|ABQ| 71159|\n",
      "|IND| 76399|\n",
      "|GRR| 27943|\n",
      "|LBB| 16006|\n",
      "|MEM|143434|\n",
      "|BTV| 12049|\n",
      "|BOS|220923|\n",
      "|PBI| 50996|\n",
      "|XNA| 27519|\n",
      "|VPS| 13917|\n",
      "|SYR| 18666|\n",
      "|JFK|239145|\n",
      "|MBS|  6887|\n",
      "|SBN|  9053|\n",
      "|PDX|104493|\n",
      "|RDD|  2866|\n",
      "|LNK|  5530|\n",
      "|HPN| 21318|\n",
      "+---+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding the total degrees\n",
    "total_degree = flight_graph.edges.select(F.col(\"src\").alias(\"id\")) \\\n",
    "    .union(flight_graph.edges.select(F.col(\"dst\").alias(\"id\"))) \\\n",
    "    .groupBy(\"id\") \\\n",
    "    .agg(F.count(\"*\").alias(\"degree\"))\n",
    "\n",
    "total_degree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|degree|\n",
      "+---+------+\n",
      "|IAH|364185|\n",
      "|JAX| 57623|\n",
      "|ABQ| 71159|\n",
      "|IND| 76399|\n",
      "|BOS|220923|\n",
      "|GRR| 27943|\n",
      "|LBB| 16006|\n",
      "|MEM|143434|\n",
      "|BTV| 12049|\n",
      "|PBI| 50996|\n",
      "|XNA| 27519|\n",
      "|VPS| 13917|\n",
      "|SYR| 18666|\n",
      "|JFK|239145|\n",
      "|MBS|  6887|\n",
      "|SBN|  9053|\n",
      "|PDX|104493|\n",
      "|RDD|  2866|\n",
      "|LNK|  5530|\n",
      "|HPN| 21318|\n",
      "+---+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For validation\n",
    "flight_graph.degrees.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle count\n",
    "\n",
    "We calculate how many times each node appears in by converting the graph into an undirected graph, then finding all triangles in the graph and finally counting how many triangles each node is part of. To find all triangles in the graph we first look for paths a -> b and b -> c and then select triangles where there is an edge c -> a. We sort the nodes of all triangles alphabetically to remove all duplicate triangles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|count|\n",
      "+---+-----+\n",
      "|IAH| 1338|\n",
      "|JAX|  342|\n",
      "|ABQ|  311|\n",
      "|IND|  612|\n",
      "|GRR|   96|\n",
      "|LBB|   23|\n",
      "|MEM| 1105|\n",
      "|BTV|   34|\n",
      "|BOS|  860|\n",
      "|PBI|  168|\n",
      "|XNA|   97|\n",
      "|VPS|   10|\n",
      "|SYR|   82|\n",
      "|JFK|  942|\n",
      "|MBS|    6|\n",
      "|SBN|   13|\n",
      "|PDX|  413|\n",
      "|RDD|    1|\n",
      "|LNK|   38|\n",
      "|HPN|   36|\n",
      "+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Removing all duplicate edges from the graph based on src and dst\n",
    "flight_edges_distinct = flight_edges.dropDuplicates(['src', 'dst'])\n",
    "\n",
    "# Making the graph undirected to mimic the built-in funtion\n",
    "undirected_edges = flight_edges_distinct.selectExpr(\"src\", \"dst\") \\\n",
    "    .union(flight_edges_distinct.selectExpr(\"dst as src\", \"src as dst\")).dropDuplicates()\n",
    "\n",
    "# Finding all a -> b, b -> c pairs \n",
    "paths = undirected_edges.alias(\"e1\") \\\n",
    "    .join(flight_edges_distinct.alias(\"e2\"), F.col(\"e1.dst\") == F.col(\"e2.src\")) \\\n",
    "    .select(F.col(\"e1.src\").alias(\"a\"),\n",
    "            F.col(\"e1.dst\").alias(\"b\"),\n",
    "            F.col(\"e2.dst\").alias(\"c\"))\n",
    "\n",
    "# Finding all triangles with c -> a\n",
    "triangles = paths \\\n",
    "    .join(undirected_edges.alias(\"e3\"), (F.col(\"e3.src\") == F.col(\"c\")) & (F.col(\"e3.dst\") == F.col(\"a\"))) \\\n",
    "    .select(\"a\", \"b\", \"c\")\n",
    "\n",
    "# Sorting the triangle nodes alphabetically to drop duplicates\n",
    "triangles_sorted = triangles.select(F.array_sort(F.array(\"a\", \"b\", \"c\")).alias(\"triangle\")).dropDuplicates()\n",
    "\n",
    "# Converting all triangles into one column of veritces [a, b, c] [c, d, a] -> a, b, c, c, d, a\n",
    "triangle_vertices = triangles_sorted.select(F.explode(\"triangle\").alias(\"id\"))\n",
    "\n",
    "# Counting the number of triangles each airport is part of \n",
    "triangle_counts = triangle_vertices.groupBy(\"id\").count()\n",
    "\n",
    "# Adding nodes that are part of 0 triangles to the result to match the built-in function\n",
    "result = flight_graph.vertices.select(\"id\") \\\n",
    "    .join(triangle_counts, on=\"id\", how=\"left\") \\\n",
    "    .withColumn(\"count\", F.coalesce(F.col(\"count\"), F.lit(0)))\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences in the results (should be empty):\n",
      "+---+--------------+------------+\n",
      "| id|Built-in_count|Custom_count|\n",
      "+---+--------------+------------+\n",
      "+---+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparing our results with the built-in function to validate all results\n",
    "joined_triangles = flight_graph.triangleCount().alias('a').join(result.alias('b'), on='id')\n",
    "diff_counts = joined_triangles.filter(F.col('a.count') != F.col('b.count')) # Should be empty if all is correct\n",
    "print(\"Differences in the results (should be empty):\")\n",
    "diff_counts.select('id', F.col('a.count').alias('Built-in_count'), F.col('b.count').alias('Custom_count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2 (1)\n",
    "Compute the total number of triangles in the graph.\n",
    "\n",
    "The query to find the total number of triangles in the graph uses the same logic as the previous query, but it just counts the total number of unique triangles, not node appearances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of triangles in the flight graph is 16015.\n"
     ]
    }
   ],
   "source": [
    "# Removing all duplicate edges from the graph based on src and dst\n",
    "flight_edges_distinct = flight_edges.dropDuplicates(['src', 'dst'])\n",
    "\n",
    "# Making the graph undirected to mimic the built-in funtion\n",
    "undirected_edges = flight_edges_distinct.selectExpr(\"src\", \"dst\") \\\n",
    "    .union(flight_edges_distinct.selectExpr(\"dst as src\", \"src as dst\")).dropDuplicates()\n",
    "\n",
    "# Finding all a -> b, b -> c pairs \n",
    "paths = undirected_edges.alias(\"e1\") \\\n",
    "    .join(flight_edges_distinct.alias(\"e2\"), F.col(\"e1.dst\") == F.col(\"e2.src\")) \\\n",
    "    .select(F.col(\"e1.src\").alias(\"a\"),\n",
    "            F.col(\"e1.dst\").alias(\"b\"),\n",
    "            F.col(\"e2.dst\").alias(\"c\"))\n",
    "\n",
    "# Finding all triangles with c -> a\n",
    "triangles = paths \\\n",
    "    .join(undirected_edges.alias(\"e3\"), (F.col(\"e3.src\") == F.col(\"c\")) & (F.col(\"e3.dst\") == F.col(\"a\"))) \\\n",
    "    .select(\"a\", \"b\", \"c\")\n",
    "\n",
    "# Sorting the triangle nodes alphabetically to drop duplicates\n",
    "triangles_sorted = triangles.select(F.array_sort(F.array(\"a\", \"b\", \"c\")).alias(\"triangle\")).dropDuplicates()\n",
    "\n",
    "# Count the total triangles in the graph\n",
    "total_triangle_count = triangles_sorted.count()\n",
    "\n",
    "print(f\"Total number of triangles in the flight graph is {total_triangle_count}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the total number of of unique triangles in the graph using the built-in function replica, we sum all the individual node triangle counts and divided it by 3 since each triangle is included three times (once for each of its 3 vertices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of triangles in the flight graph is 16015.\n"
     ]
    }
   ],
   "source": [
    "# Finding the sum of all triangles in the graph using the triangle count results from q1\n",
    "total_triangle_count = triangle_counts.agg(F.sum(\"count\")).first()[0] // 3\n",
    "print(f\"Total number of triangles in the flight graph is {total_triangle_count}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of triangles in the flight graph based on the built-in function is 16015.\n"
     ]
    }
   ],
   "source": [
    "# For validation\n",
    "triangle_count_val = flight_graph.triangleCount().agg(F.sum(\"count\")).first()[0] // 3\n",
    "print(f\"Total number of triangles in the flight graph based on the built-in function is {triangle_count_val}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precomputation for query 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_vertices_q = (flight_df\n",
    "                  .select(F.col(\"ORIGIN\").alias(\"id\"))\n",
    "                  .union(flight_df\n",
    "                        .select(F.col(\"DEST\").alias(\"id\")))\n",
    "                  .distinct()\n",
    ")\n",
    "flight_edges_q = (flight_df\n",
    "                .select(F.col('ORIGIN').alias('src'), F.col('DEST').alias('dst'), F.col('DISTANCE'))\n",
    "                .distinct()\n",
    ")\n",
    "flight_graph_q = gf.GraphFrame(flight_vertices_q, flight_edges_q)\n",
    "\n",
    "N = flight_graph_q.vertices.count()\n",
    "\n",
    "# lookup table ID:'str' -> idx:int\n",
    "indexes = {}\n",
    "i = 0\n",
    "for node in flight_graph_q.vertices.toLocalIterator():\n",
    "    indexes[node.id] = i\n",
    "    i += 1\n",
    "\n",
    "# Adjacency matrix, distance matrix\n",
    "adjM = np.zeros(N * N).reshape((N, N))\n",
    "distM = np.zeros(N * N).reshape((N, N))\n",
    "\n",
    "for edge in flight_graph_q.edges.toLocalIterator():\n",
    "    fromIdx = indexes[edge.src] \n",
    "    toIdx = indexes[edge.dst]\n",
    "    adjM[toIdx][fromIdx] = 1\n",
    "    distM[toIdx][fromIdx] = edge.DISTANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3 (2)\n",
    "Compute a centrality measure of your choice natively on Spark using Graphframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closeness Centrality\n",
    "\n",
    "# BFS function for calculating a measure of closeness centrality from a given node\n",
    "\n",
    "# Shortest path -> least edges taken\n",
    "def bfs_edges(vertices, lookup, adjM, v: str):\n",
    "    lookup = json.loads(lookup) # For mapping vertex names to their indexes\n",
    "    adjM = json.loads(adjM) # Represents graph's adjacency matrix\n",
    "    N = len(vertices)\n",
    "    distances = [float('inf')] * N # initial list of distances (all infinity)\n",
    "    distances[lookup[v]] = 0 # distance to the start node is 0\n",
    "    visited = set() # set of visited nodes (tracked by index)\n",
    "    q = [v] # queue\n",
    "\n",
    "    # Processes nodes while queue not empty\n",
    "    while len(q) != 0:\n",
    "        curr = q.pop(0) # Take the first node\n",
    "        currIdx = lookup[curr] # Get the index of current node\n",
    "        \n",
    "        # Check if the node has already been visited\n",
    "        if currIdx in visited:\n",
    "            continue\n",
    "        visited.add(currIdx) # Mark node as visited\n",
    "\n",
    "        # Check all other nodes to see if they are directly connected to the current node\n",
    "        for i in range(N):\n",
    "            # If there's an edge from current node to node i and node i has not been visited\n",
    "            if adjM[i][currIdx] == 1 and not i in visited:\n",
    "                distances[i] = min(distances[i], distances[currIdx] + 1) # If a shorter path is found then update the distance to node i\n",
    "                q.append(vertices[i])\n",
    "\n",
    "    return (N - 1)/sum(distances)\n",
    "\n",
    "# Shortest path -> actual physical shortest path\n",
    "def bfs_dist(vertices, lookup, distM, v: str):\n",
    "    lookup = json.loads(lookup) # For mapping vertex names to their indexes\n",
    "    distM = json.loads(distM) # Represents graph's adjacency matrix\n",
    "    N = len(vertices)\n",
    "    distances = [float('inf')] * N # initial list of distances (all infinity)\n",
    "    distances[lookup[v]] = 0 # distance to the start node is 0\n",
    "    visited = set() # set of visited nodes (tracked by index)\n",
    "    q = [v] # queue\n",
    "\n",
    "    # Processes nodes while queue not empty\n",
    "    while len(q) != 0:\n",
    "        curr = q.pop(0) # Take the first node\n",
    "        currIdx = lookup[curr] # Get the index of current node\n",
    "        \n",
    "        # Check if the node has already been visited\n",
    "        if currIdx in visited:\n",
    "            continue\n",
    "        visited.add(currIdx) # Mark node as visited\n",
    "\n",
    "        # Check all other nodes to see if they are directly connected to the current node\n",
    "        for i in range(N):\n",
    "            # If there's an edge from current node to node i and node i has not been visited\n",
    "            if distM[i][currIdx] != 0 and not i in visited:\n",
    "                distances[i] = min(distances[i], distances[currIdx] + distM[i][currIdx]) # If a shorter path is found then update the distance to node i\n",
    "                q.append(vertices[i])\n",
    "\n",
    "    return (N - 1)/sum(distances)\n",
    "\n",
    "bfs_edges_udf = F.udf(bfs_edges, FloatType())\n",
    "bfs_dist_udf = F.udf(bfs_dist, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+---------------+\n",
      "| id|centrality_edges|centrality_dist|\n",
      "+---+----------------+---------------+\n",
      "|IAH|       0.5983773|    7.851529E-4|\n",
      "|JAX|      0.47504026|   6.9578097E-4|\n",
      "|ABQ|      0.50687283|   7.6872966E-4|\n",
      "|IND|       0.5139373|    8.692603E-4|\n",
      "|GRR|      0.47049442|    8.364784E-4|\n",
      "|LBB|      0.40466392|    7.721947E-4|\n",
      "|MEM|       0.5662188|   8.7641896E-4|\n",
      "|BTV|      0.43382353|   6.0750963E-4|\n",
      "|BOS|      0.53636366|    5.937573E-4|\n",
      "|PBI|      0.45807454|    6.000716E-4|\n",
      "|XNA|      0.47580644|    8.764086E-4|\n",
      "|VPS|      0.42753622|   7.3864305E-4|\n",
      "|SYR|      0.43768546|    6.703997E-4|\n",
      "|JFK|       0.5462963|    6.488807E-4|\n",
      "|MBS|      0.41143653|   8.0058404E-4|\n",
      "|SBN|      0.43703705|   8.5602776E-4|\n",
      "|PDX|       0.5305755|     5.75475E-4|\n",
      "|RDD|      0.36019537|    5.204612E-4|\n",
      "|LNK|      0.45807454|    8.191714E-4|\n",
      "|HPN|      0.43255132|    6.062599E-4|\n",
      "+---+----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vertexList = [node.id for node in flight_graph_q.vertices.collect()]\n",
    "centralities = flight_graph_q.vertices.withColumn('centrality_edges', bfs_edges_udf(F.lit(vertexList), F.lit(json.dumps(indexes)), F.lit(json.dumps(adjM.tolist())), 'id'))\n",
    "centralities = centralities.withColumn('centrality_dist', bfs_dist_udf(F.lit(vertexList), F.lit(json.dumps(indexes)), F.lit(json.dumps(distM.tolist())), 'id'))\n",
    "centralities.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 4 (3)\n",
    "Implement the PageRank algorithm natively on Spark using Graphframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total number of vertices\n",
    "N = flight_vertices_q.count()\n",
    "\n",
    "# Initializing ranks by setting an equal rank to all nodes\n",
    "ranks = flight_vertices_q.withColumn(\"rank\", F.lit(1.0))\n",
    "out_degree = flight_graph_q.edges.groupBy(\"src\").agg(F.count(\"*\").alias(\"outDegree\"))\n",
    "\n",
    "damping_factor = 0.85\n",
    "num_iters = 10\n",
    "\n",
    "for i in range(num_iters):\n",
    "    # Joining edges with current ranks to find how much rank each source node contributes to its destination node\n",
    "    contributions = flight_edges_q.join(ranks, flight_edges_q.src == ranks.id).join(out_degree, on=\"src\").withColumn(\"contribution\", F.col(\"rank\") / F.col(\"outDegree\")).select(\"dst\", \"contribution\")\n",
    "    \n",
    "    # Sum the contributions for all destination nodes\n",
    "    sum_contributions = contributions.groupBy(\"dst\").agg(F.sum(\"contribution\").alias(\"incoming\"))\n",
    "\n",
    "    # Computing new rank values based on incoming contribution score (+ dampening)\n",
    "    updated_ranks = sum_contributions.withColumn(\"rank\", F.lit((1 - damping_factor)) + damping_factor * F.col(\"incoming\")).select(F.col(\"dst\").alias(\"id\"), \"rank\")\n",
    "\n",
    "    # Updating ranks dataframe\n",
    "    # joining with vetrices to ensure all nodes have a rank value even if they were unaffected by this iteration\n",
    "    ranks = flight_vertices_q.join(updated_ranks, on=\"id\", how=\"left_outer\").withColumn(\"rank\", F.coalesce(F.col(\"rank\"), F.lit((1 - damping_factor) / N))).select(\"id\", \"rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = flight_graph_q.pageRank(resetProbability=0.15, maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------------+\n",
      "| id|           pagerank|               rank|\n",
      "+---+-------------------+-------------------+\n",
      "|IAH|  5.662321605756482|  5.662321605756484|\n",
      "|JAX| 1.6077915704615784| 1.6077915704615786|\n",
      "|ABQ| 1.7429124686716673| 1.7429124686716668|\n",
      "|IND| 1.9850210090574687| 1.9850210090574683|\n",
      "|GRR|  0.836374678808676| 0.8363746788086759|\n",
      "|LBB| 0.5372659782130557| 0.5372659782130556|\n",
      "|MEM|  4.676034097666703|  4.676034097666703|\n",
      "|BTV| 0.5764612714461971| 0.5764612714461971|\n",
      "|BOS| 2.8138753782688175| 2.8138753782688166|\n",
      "|PBI| 1.1467079819343051| 1.1467079819343051|\n",
      "|XNA|   0.89689132633325| 0.8968913263332497|\n",
      "|VPS|0.40682553897292073| 0.4068255389729206|\n",
      "|SYR| 0.7563288719817197| 0.7563288719817195|\n",
      "|JFK|  3.508955992981467| 3.5089559929814675|\n",
      "|MBS| 0.3536217424004337|0.35362174240043376|\n",
      "|SBN|0.41375417295624806|0.41375417295624806|\n",
      "|PDX| 2.3823714398188938| 2.3823714398188933|\n",
      "|RDD| 0.2915821901287276| 0.2915821901287276|\n",
      "|LNK| 0.5806182004896793| 0.5806182004896793|\n",
      "|HPN| 0.6290724318775694| 0.6290724318775694|\n",
      "+---+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = result.vertices.join(ranks, on='id', how='inner')\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 5 (4)\n",
    "Find the group of the most connected airports.\n",
    "\n",
    "To find the group of most connected components, we replicated the connectedComponents() function. As preparation we removed all duplicate edges for less processing.\n",
    "\n",
    "To find all connected components, we first initialized the components so that each node belongs to a separate component. After this, we added all nodes that are reachable from the initial node to respective components. This process is repeated until the results converge (in this specific case, it takes 4 iterations, and the graph is fully connected). Finally, the largest connected component is identified by selecting the component with the largest size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: 42 components.\n",
      "Iteration 2: 7 components.\n",
      "Iteration 3: 2 components.\n",
      "Iteration 4: 1 components.\n",
      "The most connected group contains 296 out of 296 airports.\n"
     ]
    }
   ],
   "source": [
    "# Removing all duplicate edges from the graph based on src and dst\n",
    "flight_edges_distinct = flight_edges.dropDuplicates(['src', 'dst'])\n",
    "\n",
    "# Creating initial components where each node starts as its own component\n",
    "components = flight_vertices.select(\"id\").withColumnRenamed(\"id\", \"node\").withColumn(\"label\", F.col(\"node\"))\n",
    "\n",
    "# After 4 iterations there is 1 large component (meaning the graph is fully connected)\n",
    "for i in range(4):\n",
    "    # Joining the edges with the components to propagate the component labels from neighbors\n",
    "    neighbors = flight_edges_distinct.join(components, flight_edges_distinct.src == components.node, \"left\") \\\n",
    "        .select(F.col(\"dst\").alias(\"node\"), \"label\") \\\n",
    "        .repartition(200, \"node\")\n",
    "\n",
    "    # Updating the components using the alpabetically first node as the label for the component\n",
    "    components = neighbors.groupBy(\"node\") \\\n",
    "        .agg(F.min(\"label\").alias(\"label\")) \\\n",
    "        .repartition(200, \"node\")\n",
    "\n",
    "    # Counting the number of connected components after this iteration for tracking\n",
    "    component_sizes = components.groupBy(\"label\").agg(F.count(\"*\").alias(\"size\"))\n",
    "    print(f\"Iteration {i+1}: {component_sizes.count()} components.\")\n",
    "\n",
    "# Extracting the largest component label (alpabetically first node)\n",
    "largest_component_label = component_sizes.orderBy(F.desc(\"size\")).limit(1).collect()[0][\"label\"]\n",
    "most_connected_airports = components.filter(F.col(\"label\") == largest_component_label).select(\"node\")\n",
    "\n",
    "print(f\"The most connected group contains {most_connected_airports.count()} out of {flight_vertices.count()} airports.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 109803845193651,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Practice session - Graphframes",
   "notebookOrigID": 2259387480520179,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
